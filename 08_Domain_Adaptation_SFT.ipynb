{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4puA1YxUZxJe"
   },
   "source": [
    "# Chapter 08: 도메인 적응 SFT\n",
    "\n",
    "## 1. 학습 목표\n",
    "\n",
    "* 도메인 특화 데이터셋(금융, 의료, 코딩)의 특성을 이해한다.\n",
    "* 시스템 프롬프트를 활용하여 모델에 전문가 페르소나를 부여한다.\n",
    "* 금융 데이터셋을 사용하여 전문 지식을 갖춘 모델을 학습한다.\n",
    "* 도메인 적응 시 고려해야 할 전략(용어 일관성, 면책 조항 등)을 학습한다.\n",
    "\n",
    "## 2. 도메인 적응(Domain Adaptation)이란?\n",
    "\n",
    "일반적인 LLM은 위키피디아나 웹 문서를 통해 넓고 얕은 지식을 가지고 있다. 하지만 특정 분야의 전문가처럼 행동하려면 해당 분야의 **전문 데이터**를 집중적으로 학습해야 한다.\n",
    "\n",
    "* **일반 모델**: \"주식 시장이 뭐야?\" -> 일반적인 정의 설명\n",
    "* **금융 특화 모델**: \"주식 시장이 뭐야?\" -> 자본 조달 기능, 유동성 공급, 가격 발견 기능 등 전문적 관점에서 설명\n",
    "\n",
    "## 3. 도메인 데이터셋 준비\n",
    "\n",
    "각 분야별로 대표적인 오픈소스 데이터셋들이 존재한다. 이번 실습에서는 금융 분야의 `gbharti/finance-alpaca`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bPjXCIpXZxJe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금융 데이터셋 로딩 중...\n",
      "데이터 개수: 1000\n",
      "샘플 데이터:\n",
      "{'instruction': 'For a car, what scams can be plotted with 0% financing vs rebate?', 'input': '', 'output': \"The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.\", 'text': ''}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 도메인별 대표 데이터셋 (참고용)\n",
    "domain_datasets = {\n",
    "    \"금융\": \"gbharti/finance-alpaca\",\n",
    "    \"의료\": \"medalpaca/medical_meadow_medical_flashcards\",\n",
    "    \"코딩\": \"TokenBender/code_instructions_122k_alpaca_style\"\n",
    "}\n",
    "\n",
    "# 1. 금융 데이터셋 로드\n",
    "print(\"금융 데이터셋 로딩 중...\")\n",
    "dataset = load_dataset(\"gbharti/finance-alpaca\", split=\"train[:1000]\")\n",
    "\n",
    "print(f\"데이터 개수: {len(dataset)}\")\n",
    "print(f\"샘플 데이터:\\n{dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHu8j0HYZxJf"
   },
   "source": [
    "## 4. 시스템 프롬프트 설계 (페르소나 주입)\n",
    "\n",
    "도메인 적응의 핵심은 모델에게 **\"당신은 전문가입니다\"**라고 최면을 거는 것이다. 이를 위해 데이터 포맷팅 단계에서 시스템 프롬프트를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L0XUQL5hZxJf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[포맷팅된 데이터 샘플]\n",
      "### System:\n",
      "당신은 금융 전문가 AI 어시스턴트이다. 질문에 대해 전문적이고 분석적인 답변을 제공하라.\n",
      "\n",
      "### Instruction:\n",
      "For a car, what scams can be plotted with 0% financing vs rebate?\n",
      "\n",
      "### Response:\n",
      "The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.\n"
     ]
    }
   ],
   "source": [
    "def format_domain_instruction(example, domain=\"금융\"):\n",
    "    \"\"\"\n",
    "    도메인별 시스템 프롬프트를 적용하여 데이터를 포맷팅하는 함수다.\n",
    "    \"\"\"\n",
    "    # 도메인별 시스템 프롬프트 정의\n",
    "    system_prompts = {\n",
    "        \"금융\": \"당신은 금융 전문가 AI 어시스턴트이다. 질문에 대해 전문적이고 분석적인 답변을 제공하라.\",\n",
    "        \"의료\": \"당신은 의료 정보 AI 어시스턴트이다. 의학적 사실에 기반하여 답변하되, 반드시 전문가와의 상담을 권유하라.\",\n",
    "        \"법률\": \"당신은 법률 전문가 AI 어시스턴트이다. 관련 법령과 판례에 기반하여 답변하되, 법적 효력이 없음을 명시하라.\"\n",
    "    }\n",
    "\n",
    "    instruction = example['instruction']\n",
    "    input_text = example.get('input', '')\n",
    "    output = example['output']\n",
    "\n",
    "    # 해당 도메인의 시스템 프롬프트 선택\n",
    "    sys_prompt = system_prompts.get(domain, \"당신은 유용한 AI 어시스턴트이다.\")\n",
    "\n",
    "    # 프롬프트 구성\n",
    "    if input_text:\n",
    "        text = f\"\"\"### System:\n",
    "{sys_prompt}\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input_text}\n",
    "\n",
    "### Response:\n",
    "{output}\"\"\"\n",
    "    else:\n",
    "        text = f\"\"\"### System:\n",
    "{sys_prompt}\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{output}\"\"\"\n",
    "\n",
    "    return {\"text\": text}\n",
    "\n",
    "# 금융 도메인으로 포맷팅 적용\n",
    "formatted_dataset = dataset.map(lambda x: format_domain_instruction(x, \"금융\"))\n",
    "\n",
    "print(\"\\n[포맷팅된 데이터 샘플]\")\n",
    "print(formatted_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QK1Sb3v6ZxJf"
   },
   "source": [
    "## 5. 모델 로드 및 학습 설정 (QLoRA)\n",
    "\n",
    "이전 챕터에서 검증된 QLoRA 설정을 그대로 사용하여 효율적으로 학습한다. 베이스 모델은 `gpt-oss-20b` (실습용 `Qwen/Qwen2.5-14B`)를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MXFP4 quantization requires Triton and kernels installed: CUDA requires Triton >= 3.4.0, XPU requires Triton >= 3.5.0, we will default to dequantizing the model to bf16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9165a4dc65414389bb0038198d903e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 준비 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# 1. 모델 로드 (4-bit QLoRA)\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "#model_id = \"Qwen/Qwen3-14B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\" # Qwen3-14B의 경우 \"sdpa\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 2. 학습 전처리\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# 3. LoRA 어댑터 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print(\"모델 준비 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWLUMO5pZxJf"
   },
   "source": [
    "## 6. 학습 실행\n",
    "\n",
    "도메인 적응 학습은 일반적인 SFT와 동일한 파이프라인을 따르지만, **과적합(Overfitting)**에 주의해야 한다. 도메인 지식을 배우려다 일반적인 대화 능력을 잃어버릴 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mK6CXPgQZxJf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금융 도메인 적응 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkubwai\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/josh/llm-finetuning/wandb/run-20251225_121403-cj6pf46m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kubwai/huggingface/runs/cj6pf46m' target=\"_blank\">denim-glitter-6</a></strong> to <a href='https://wandb.ai/kubwai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kubwai/huggingface' target=\"_blank\">https://wandb.ai/kubwai/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kubwai/huggingface/runs/cj6pf46m' target=\"_blank\">https://wandb.ai/kubwai/huggingface/runs/cj6pf46m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 07:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.264800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 완료!\n"
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./GPT-OSS-20B-finance\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    optim=\"paged_adamw_8bit\",      # 메모리 효율화\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    #max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    ")\n",
    "\n",
    "# Trainer 생성\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=formatted_dataset,\n",
    "    args=training_args,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"금융 도메인 적응 학습 시작...\")\n",
    "trainer.train()\n",
    "print(\"학습 완료!\")\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model(\"./GPT-OSS-20B-financ-final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9zegWYPZxJf"
   },
   "source": [
    "## 7. 도메인 적응 핵심 전략\n",
    "\n",
    "성공적인 도메인 모델을 만들기 위해 반드시 고려해야 할 4가지 전략이다.\n",
    "\n",
    "1. **전문 데이터셋 수집**: 인터넷 긁어모으기(Crawling)보다는 교과서, 논문, 사내 문서 등 검증된 데이터를 사용해야 한다. 가능하다면 도메인 전문가(SME)의 검수를 거치는 것이 좋다.\n",
    "2. **시스템 프롬프트 활용**: 모델에게 역할을 명확히 부여하면 말투와 전문 용어 사용 빈도가 달라진다.\n",
    "3. **용어 일관성 (Terminology)**: 같은 개념을 다르게 부르지 않도록 데이터셋 내에서 용어를 통일해야 한다.\n",
    "4. **면책 조항 (Disclaimer)**: 특히 의료(Medical)나 법률(Legal) 분야는 모델이 환각(Hallucination)을 일으킬 경우 치명적일 수 있다. 시스템 프롬프트에 \"전문가와 상의하십시오\"라는 문구를 필수적으로 포함해야 한다.\n",
    "\n",
    "## 8. 요약\n",
    "\n",
    "이 챕터에서는 금융 데이터셋과 시스템 프롬프트를 결합하여 모델을 금융 전문가로 튜닝하는 방법을 실습했다. 도메인 적응은 단순히 데이터를 넣는 것을 넘어, 모델의 **페르소나**를 정의하고 **전문 지식**을 체계적으로 주입하는 과정임을 이해했다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

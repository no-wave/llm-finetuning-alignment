{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wb5sCVRvUq1A"
   },
   "source": [
    "# Chapter 02: Fine-tuning 유형 및 방법론\n",
    "\n",
    "## 1. 학습 목표\n",
    "\n",
    "* Full, Partial, PEFT Fine-tuning의 차이점과 장단점을 이해한다.\n",
    "* LoRA, QLoRA, DoRA의 원리를 파악하고 구현 방법을 익힌다.\n",
    "* 상황에 맞는 최적의 Fine-tuning 전략을 선택할 수 있다.\n",
    "* gpt-oss-20b 모델에 적합한 학습 설정을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wb5sCVRvUq1A"
   },
   "source": [
    "## 2. Fine-tuning 유형 분류\n",
    "\n",
    "Fine-tuning은 **학습 대상 가중치**의 범위에 따라 크게 세 가지 유형으로 분류된다.\n",
    "\n",
    "```text\n",
    "Fine-tuning 유형\n",
    "├── Full Fine-tuning: 모든 가중치(100%) 학습\n",
    "├── Partial Tuning: 일부 레이어(10~50%) 학습\n",
    "└── PEFT (Parameter-Efficient): 새로운 소규모 가중치(0.1~1%) 학습\n",
    "\n",
    "```\n",
    "\n",
    "### 2.1 유형별 비교\n",
    "\n",
    "| 특성 | Full Fine-tuning | Partial Tuning | PEFT (LoRA 등) |\n",
    "| --- | --- | --- | --- |\n",
    "| **학습 파라미터** | 전체 (100%) | 일부 (10-50%) | 극소수 (0.1-1%) |\n",
    "| **VRAM 요구량** | 매우 높음 (모델 크기의 4배 이상) | 높음 | 낮음 (모델 크기와 유사) |\n",
    "| **성능 잠재력** | 최고 | 중상 | 높음 (Full 대비 95-99%) |\n",
    "| **망각 위험** | 높음 | 중간 | 낮음 |\n",
    "| **권장도 (2025)** | 낮음 (연구 목적) | 낮음 | **매우 높음 (표준)** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wb5sCVRvUq1A"
   },
   "source": [
    "## 3. Full Fine-tuning\n",
    "\n",
    "### 3.1 개념\n",
    "\n",
    "모델의 **모든 파라미터**를 학습 데이터로 업데이트하는 방식이다. 가장 전통적인 방식이지만, 모델 크기가 커짐에 따라 기하급수적으로 늘어나는 VRAM 요구량으로 인해 대형 모델에서는 거의 사용되지 않는다.\n",
    "\n",
    "### 3.2 구현 코드 (개념적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "10-IKc3RUq1C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josh/anaconda3/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "MXFP4 quantization requires Triton and kernels installed: CUDA requires Triton >= 3.4.0, XPU requires Triton >= 3.5.0, we will default to dequantizing the model to bf16\n",
      "Fetching 3 files: 100%|██████████| 3/3 [00:40<00:00, 13.65s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:48<00:00, 16.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 학습 가능 파라미터 수: 20914757184\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai/gpt-oss-20b\")\n",
    "\n",
    "# Full Fine-tuning 설정: 모든 파라미터의 그래디언트 계산 활성화\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"전체 학습 가능 파라미터 수: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF0dKL5LUq1D"
   },
   "source": [
    "## 4. Parameter-Efficient Fine-tuning (PEFT)\n",
    "\n",
    "2025년 현재, LLM Fine-tuning의 표준은 PEFT다. 기존 가중치를 동결(Freeze)하고 **새로운 소규모 학습 가능한 파라미터**를 추가하거나, 특정 부분만 학습하여 메모리 효율성과 성능을 동시에 잡는다.\n",
    "\n",
    "### 4.1 LoRA (Low-Rank Adaptation)\n",
    "\n",
    "#### 핵심 원리\n",
    "\n",
    "거대 언어 모델의 가중치 행렬은 \"Intrinsic Rank(본질적 차원)\"가 낮다는 가설에 기반한다. 즉, 전체 가중치를 다 바꿀 필요 없이, **저순위(Low-Rank) 분해**된 작은 행렬 두 개(, )만 학습해도 충분한 변화를 줄 수 있다.\n",
    "\n",
    "```text\n",
    "수식: W' = W + ΔW = W + (A × B)\n",
    "- W: 원본 가중치 (동결)\n",
    "- A: d × r 행렬 (학습)\n",
    "- B: r × d 행렬 (학습)\n",
    "- r: Rank (매우 작은 값, 예: 8, 16)\n",
    "\n",
    "```\n",
    "\n",
    "#### 파라미터 절감 효과\n",
    "\n",
    "4096 × 4096 크기의 가중치 행렬을 예로 들면:\n",
    "\n",
    "* **Full Fine-tuning**: 16,777,216개 파라미터 학습\n",
    "* **LoRA (r=8)**: (4096×8) + (8×4096) = 65,536개 파라미터 학습\n",
    "* **결과**: 약 **256배**의 파라미터 절감 효과가 있다.\n",
    "\n",
    "#### LoRA 레이어 구현 예시\n",
    "\n",
    "LoRA의 작동 원리를 이해하기 위한 간단한 PyTorch 구현이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yQv4w7ItUq1D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 가능 파라미터: 65,536\n",
      "전체 파라미터: 16,846,848\n",
      "학습 비율: 0.3890%\n"
     ]
    }
   ],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    \"\"\"\n",
    "    LoRA 레이어의 원리를 보여주는 간단한 구현이다.\n",
    "    원본 가중치는 동결하고 저순위 행렬 A, B만 학습한다.\n",
    "    \"\"\"\n",
    "    def __init__(self, original_layer, rank=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.original_layer = original_layer\n",
    "\n",
    "        # 원본 레이어 동결 (핵심)\n",
    "        for param in self.original_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # 입력/출력 차원 획득\n",
    "        in_features = original_layer.in_features\n",
    "        out_features = original_layer.out_features\n",
    "\n",
    "        # LoRA 행렬 A, B 초기화\n",
    "        # A는 정규분포, B는 0으로 초기화하여 학습 시작 시 원본과 동일한 출력을 보장한다.\n",
    "        self.lora_A = nn.Parameter(torch.randn(in_features, rank) * 0.01)\n",
    "        self.lora_B = nn.Parameter(torch.zeros(rank, out_features))\n",
    "\n",
    "        # 스케일링 팩터 (학습률과 유사한 역할)\n",
    "        self.scaling = alpha / rank\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. 원본 경로 (Frozen)\n",
    "        original_output = self.original_layer(x)\n",
    "\n",
    "        # 2. LoRA 경로 (Trainable): x @ A @ B\n",
    "        lora_output = (x @ self.lora_A @ self.lora_B) * self.scaling\n",
    "\n",
    "        # 3. 최종 합산\n",
    "        return original_output + lora_output\n",
    "\n",
    "# 사용 예시\n",
    "original = nn.Linear(4096, 4096)\n",
    "lora_layer = LoRALayer(original, rank=8, alpha=16)\n",
    "\n",
    "trainable = sum(p.numel() for p in lora_layer.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in lora_layer.parameters())\n",
    "\n",
    "print(f\"학습 가능 파라미터: {trainable:,}\")\n",
    "print(f\"전체 파라미터: {total:,}\")\n",
    "print(f\"학습 비율: {trainable/total*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi0FF-KzUq1D"
   },
   "source": [
    "### 4.2 QLoRA (Quantized LoRA)\n",
    "\n",
    "#### 개념\n",
    "\n",
    "LoRA에 **4-bit 양자화(Quantization)**를 결합하여 메모리 사용량을 극단적으로 줄인 방식이다. 소비자용 GPU(RTX 3090/4090)에서도 거대 모델을 학습할 수 있게 해주는 핵심 기술이다.\n",
    "\n",
    "#### 핵심 기술 3가지\n",
    "\n",
    "1. **4-bit NormalFloat (NF4)**: 정규분포를 따르는 가중치에 최적화된 새로운 데이터 타입이다. 정보 손실을 최소화한다.\n",
    "2. **Double Quantization**: 양자화에 사용되는 상수(Quantization Constant)조차 양자화하여 추가적인 메모리를 절약한다.\n",
    "3. **Paged Optimizers**: GPU 메모리가 부족할 때 CPU RAM을 자동으로 활용하여 OOM(Out of Memory) 오류를 방지한다.\n",
    "\n",
    "#### 메모리 비교 (20B 모델 기준)\n",
    "\n",
    "| 방식 | 모델 로드 | 학습 오버헤드 | 총 필요 VRAM |\n",
    "| --- | --- | --- | --- |\n",
    "| Full (FP16) | 40 GB | 120 GB+ | 160 GB+ (A100 4장) |\n",
    "| LoRA (FP16) | 40 GB | 2 GB | 45 GB (A100 1장) |\n",
    "| **QLoRA (4-bit)** | **10 GB** | **2 GB** | **14~16 GB (RTX 4090)** |\n",
    "\n",
    "### 4.3 DoRA (Weight-Decomposed LoRA)\n",
    "\n",
    "2024년에 발표된 LoRA의 개선판이다. 가중치를 **크기(Magnitude)**와 **방향(Direction)**으로 분해하여 학습한다.\n",
    "\n",
    "* **원리**:\n",
    "*  (크기): 벡터로 직접 학습\n",
    "*  (방향): LoRA로 학습\n",
    "\n",
    "\n",
    "* **장점**: LoRA보다 학습 안정성이 높고, 낮은 Rank에서도 Full Fine-tuning에 가까운 성능을 낸다.\n",
    "* **사용법**: `peft` 라이브러리에서 `use_dora=True` 옵션만 켜면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi0FF-KzUq1D"
   },
   "source": [
    "## 5. 학습 방법 선택 가이드\n",
    "\n",
    "상황에 따라 어떤 방법을 선택해야 할지 결정하는 가이드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ct3TD1AWUq1D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 조건: VRAM 24GB, 모델 20B, 목표 '가성비'\n",
      "추천: QLoRA + SFT\n",
      "  - 가장 효율적이며 성능 저하가 거의 없다.\n",
      "  - bitsandbytes 라이브러리 활용 필수.\n"
     ]
    }
   ],
   "source": [
    "def recommend_finetuning_method(gpu_vram_gb, model_size_b, goal):\n",
    "    \"\"\"\n",
    "    하드웨어와 목적에 따른 Fine-tuning 방식을 추천하는 함수다.\n",
    "    \"\"\"\n",
    "    print(f\"분석 조건: VRAM {gpu_vram_gb}GB, 모델 {model_size_b}B, 목표 '{goal}'\")\n",
    "\n",
    "    # 1. 메모리 제약 확인\n",
    "    # 4-bit 모델 크기(GB) ≈ 파라미터 수 / 2\n",
    "    required_vram_qlora = (model_size_b / 2) * 1.5\n",
    "\n",
    "    if gpu_vram_gb < required_vram_qlora:\n",
    "        print(\"결과: 학습 불가능. 더 높은 VRAM의 GPU가 필요하다.\")\n",
    "        return\n",
    "\n",
    "    # 2. 방식 추천\n",
    "    if goal == \"최고 성능\" and gpu_vram_gb > model_size_b * 8:\n",
    "        print(\"추천: Full Fine-tuning (자원이 충분함)\")\n",
    "    elif goal == \"일반적인 목적\" or goal == \"가성비\":\n",
    "        print(\"추천: QLoRA + SFT\")\n",
    "        print(\"  - 가장 효율적이며 성능 저하가 거의 없다.\")\n",
    "        print(\"  - bitsandbytes 라이브러리 활용 필수.\")\n",
    "    elif goal == \"성능 최적화\" and \"메모리 여유\" in goal:\n",
    "        print(\"추천: DoRA (Weight-Decomposed LoRA)\")\n",
    "        print(\"  - LoRA보다 높은 학습 안정성과 성능을 제공한다.\")\n",
    "    elif goal == \"추론 속도\":\n",
    "        print(\"추천: LoRA/QLoRA 학습 후 병합(Merge)\")\n",
    "        print(\"  - 학습된 어댑터를 베이스 모델에 합쳐 단일 모델로 배포한다.\")\n",
    "\n",
    "# gpt-oss-20b 기준 추천 시뮬레이션\n",
    "recommend_finetuning_method(gpu_vram_gb=24, model_size_b=20, goal=\"가성비\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuL_YrAgUq1D"
   },
   "source": [
    "## 6. gpt-oss-20b를 위한 권장 설정\n",
    "\n",
    "gpt-oss-20b 모델을 RTX 3090/4090급(24GB VRAM) 환경에서 학습하기 위한 최적의 설정을 정리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1HQVb3znUq1E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-oss-20b 권장 설정 구성 완료\n",
      "\n",
      "[quantization]\n",
      "  load_in_4bit: True\n",
      "  bnb_4bit_quant_type: nf4\n",
      "  bnb_4bit_compute_dtype: bfloat16\n",
      "  bnb_4bit_use_double_quant: True\n",
      "\n",
      "[lora]\n",
      "  r: 16\n",
      "  lora_alpha: 32\n",
      "  target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
      "  lora_dropout: 0.05\n",
      "  bias: none\n",
      "  task_type: CAUSAL_LM\n"
     ]
    }
   ],
   "source": [
    "# gpt-oss-20b QLoRA 권장 설정\n",
    "recommended_config = {\n",
    "    # 1. 모델 양자화 설정 (QLoRA 핵심)\n",
    "    \"quantization\": {\n",
    "        \"load_in_4bit\": True,\n",
    "        \"bnb_4bit_quant_type\": \"nf4\",           # NormalFloat 4-bit\n",
    "        \"bnb_4bit_compute_dtype\": \"bfloat16\",   # 연산 정밀도\n",
    "        \"bnb_4bit_use_double_quant\": True       # 이중 양자화\n",
    "    },\n",
    "\n",
    "    # 2. LoRA 설정\n",
    "    \"lora\": {\n",
    "        \"r\": 16,                    # Rank: 16~32 권장 (복잡한 태스크는 64)\n",
    "        \"lora_alpha\": 32,           # Alpha: Rank의 2배\n",
    "        \"target_modules\": [         # 모든 Linear 레이어에 적용 권장\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "        ],\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"bias\": \"none\",\n",
    "        \"task_type\": \"CAUSAL_LM\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"gpt-oss-20b 권장 설정 구성 완료\")\n",
    "for category, conf in recommended_config.items():\n",
    "    print(f\"\\n[{category}]\")\n",
    "    for k, v in conf.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28NrSDMuUq1E"
   },
   "source": [
    "## 7. 요약\n",
    "\n",
    "이번 챕터에서는 Fine-tuning의 다양한 방법론을 비교하고, 현실적인 제약 하에서 최적의 선택지인 **QLoRA**와 최신 기법인 **DoRA**에 대해 학습했다.\n",
    "\n",
    "* **Full Fine-tuning**은 성능은 좋지만 막대한 자원이 필요하여 실무에서는 제한적으로 사용된다.\n",
    "* **LoRA**는 가중치 행렬을 저순위 분해하여 파라미터를 획기적으로 줄이는 기술이다.\n",
    "* **QLoRA**는 4-bit 양자화를 통해 20B급 모델도 소비자용 GPU에서 학습 가능하게 만든다.\n",
    "* **DoRA**는 크기와 방향을 분리하여 학습 안정성을 높인 LoRA의 발전형이다.\n",
    "\n",
    "다음 챕터에서는 이러한 학습을 진행하기 위해 가장 중요한 원료인 **데이터셋 준비** 과정을 다룬다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
